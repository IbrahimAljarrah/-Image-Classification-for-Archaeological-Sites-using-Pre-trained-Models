{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjYX410Yabc-",
        "outputId": "4923366a-005a-46ad-f632-b708c38d708c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_docs\n",
            "  Downloading tensorflow_docs-2023.5.24.56664-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.6/183.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (1.4.0)\n",
            "Collecting astor (from tensorflow_docs)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (3.1.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (5.9.2)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow_docs) (2.1.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (5.7.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (0.17.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow_docs) (4.1.0)\n",
            "Installing collected packages: astor, tensorflow_docs\n",
            "Successfully installed astor-0.8.1 tensorflow_docs-2023.5.24.56664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KYz1ZWF0O0Qg"
      },
      "outputs": [],
      "source": [
        "#===============Import the required libraries===============\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import *\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "#===============Import the required libraries==============="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 999\n",
        "np.random.seed(SEED)\n",
        "\n",
        "def load_images_and_labels(image_paths, target_size=(32, 32)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = load_img(image_path, target_size=target_size)\n",
        "        image = img_to_array(image)\n",
        "\n",
        "        label = image_path.split(os.path.sep)[-2]\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "def load_image_paths(drive_folder_path, image_types=('*.jpg', '*.png', '*.jpeg', '*.gif')):\n",
        "    image_paths = []\n",
        "    classes = []\n",
        "\n",
        "    # Get the list of subfolders inside the main folder\n",
        "    subfolders = [f.path for f in os.scandir(drive_folder_path) if f.is_dir()]\n",
        "\n",
        "    for folder in subfolders:\n",
        "        class_name = os.path.basename(folder)  # Get the name of the folder as the class\n",
        "        class_images = []\n",
        "\n",
        "        # Iterate over specified image types\n",
        "        for image_type in image_types:\n",
        "            class_images.extend(glob(os.path.join(folder, image_type)))\n",
        "\n",
        "        image_paths.extend(class_images)\n",
        "        classes.extend([class_name] * len(class_images))\n",
        "\n",
        "    return image_paths, classes\n",
        "\n",
        "\n",
        "\n",
        "def build_network(width, height, depth, classes):\n",
        "\n",
        "    input_layer = Input(shape=(width, height, depth))\n",
        "\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(input_layer)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    #x = Dropout(rate=0.25)(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(input_layer)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    #x = Dropout(rate=0.25)(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(input_layer)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "   # x = Dropout(rate=0.25)(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    #x = Dropout(rate=0.25)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=512)(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "  #  x = Dropout(rate=0.25)(x)\n",
        "    x = Dense(units=classes)(x)\n",
        "\n",
        "    output = Softmax()(x)\n",
        "    return Model(input_layer, output)\n",
        "\n",
        "\n",
        "def plot_model_history(model_history, metric, plot_name):\n",
        "    \"\"\"\n",
        "    * plot and save a model's training curve\n",
        "    \"\"\"\n",
        "    sns.set(style='darkgrid')  # Use Seaborn directly to set the style\n",
        "    plotter = tfdocs.plots.HistoryPlotter()\n",
        "    plotter.plot({'Model': model_history}, metric=metric)\n",
        "    plt.title(f'{metric.upper()}')\n",
        "    plt.ylim([0, 1])\n",
        "    plt.savefig(f'{plot_name}.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "w4AiiPtOPyI5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load the dataset into memory, normalizing the images and one-hot encoding the labels\n",
        "    drive_folder_path = '/content/drive/MyDrive/Archaeological_Sites_Classification'  # Update with your actual folder path\n",
        "    image_paths, classes = load_image_paths(drive_folder_path)\n",
        "    X, y = load_images_and_labels(image_paths)\n",
        "    X = X.astype('float') / 255.0\n",
        "    label_binarizer = LabelBinarizer()\n",
        "    y = label_binarizer.fit_transform(y)\n",
        "\n",
        "    # Display class distribution\n",
        "    class_df = pd.DataFrame({'Class': classes})\n",
        "    print(class_df['Class'].value_counts())\n",
        "\n",
        "    (X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.33)\n",
        "    print(f'Shape of X_train: {X_train.shape}')\n",
        "    print(f'Shape of X_test: {X_test.shape}')\n",
        "    print(f'Shape of y_train: {y_train.shape}')\n",
        "    print(f'Shape of y_test: {y_test.shape}')\n",
        "\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 6\n",
        "\n",
        "    # Before Augmentation\n",
        "    model = build_network(32, 32, 3, len(label_binarizer.classes_))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "\n",
        "    result = model.evaluate(X_test, y_test)\n",
        "    print(f'Test accuracy: {result[1]}')\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    print(classification_report(y_true_classes, y_pred_classes, target_names=label_binarizer.classes_))\n",
        "\n",
        "    plot_model_history(history, 'accuracy', 'normal')\n",
        "\n",
        "    # After Augmentation\n",
        "    model = build_network(32, 32, 3, len(label_binarizer.classes_))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    augmenter = ImageDataGenerator(\n",
        "        horizontal_flip=True, rotation_range=30, width_shift_range=0.1,\n",
        "        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, fill_mode='nearest'\n",
        "    )\n",
        "    train_generator = augmenter.flow(X_train, y_train, BATCH_SIZE)\n",
        "    hist = model.fit(train_generator, validation_data=(X_test, y_test), epochs=EPOCHS)\n",
        "\n",
        "    result = model.evaluate(X_test, y_test)\n",
        "    print(f'Test accuracy: {result[1]}')\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    print(classification_report(y_true_classes, y_pred_classes, target_names=label_binarizer.classes_))\n",
        "    plot_model_history(hist, 'accuracy', 'augmented')\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XJ0yRUnPyMT",
        "outputId": "12cd6974-df96-4ba8-de9b-8839dba5309f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "um_qais          811\n",
            "jarash           703\n",
            "Wadi_Rum         614\n",
            "Petra            607\n",
            "Ajloun           572\n",
            "Roman_Theater    520\n",
            "Name: Class, dtype: int64\n",
            "Shape of X_train: (2564, 32, 32, 3)\n",
            "Shape of X_test: (1263, 32, 32, 3)\n",
            "Shape of y_train: (2564, 6)\n",
            "Shape of y_test: (1263, 6)\n",
            "Epoch 1/50\n",
            "428/428 [==============================] - 30s 62ms/step - loss: 1.5841 - accuracy: 0.4758 - val_loss: 2.9276 - val_accuracy: 0.3017\n",
            "Epoch 2/50\n",
            "428/428 [==============================] - 28s 66ms/step - loss: 1.1699 - accuracy: 0.5546 - val_loss: 1.2659 - val_accuracy: 0.5859\n",
            "Epoch 3/50\n",
            "428/428 [==============================] - 25s 59ms/step - loss: 1.0320 - accuracy: 0.6209 - val_loss: 1.1246 - val_accuracy: 0.6184\n",
            "Epoch 4/50\n",
            "428/428 [==============================] - 24s 55ms/step - loss: 0.9334 - accuracy: 0.6490 - val_loss: 1.3057 - val_accuracy: 0.5867\n",
            "Epoch 5/50\n",
            "428/428 [==============================] - 25s 58ms/step - loss: 0.8352 - accuracy: 0.6923 - val_loss: 1.1100 - val_accuracy: 0.6247\n",
            "Epoch 6/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.7526 - accuracy: 0.7157 - val_loss: 1.0785 - val_accuracy: 0.6310\n",
            "Epoch 7/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 0.6846 - accuracy: 0.7523 - val_loss: 1.2545 - val_accuracy: 0.6326\n",
            "Epoch 8/50\n",
            "428/428 [==============================] - 23s 53ms/step - loss: 0.6092 - accuracy: 0.7777 - val_loss: 1.2974 - val_accuracy: 0.6184\n",
            "Epoch 9/50\n",
            "428/428 [==============================] - 24s 56ms/step - loss: 0.5753 - accuracy: 0.7906 - val_loss: 1.7053 - val_accuracy: 0.5392\n",
            "Epoch 10/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.4859 - accuracy: 0.8284 - val_loss: 2.6270 - val_accuracy: 0.4125\n",
            "Epoch 11/50\n",
            "428/428 [==============================] - 23s 55ms/step - loss: 0.5184 - accuracy: 0.8120 - val_loss: 1.4477 - val_accuracy: 0.6279\n",
            "Epoch 12/50\n",
            "428/428 [==============================] - 24s 56ms/step - loss: 0.5566 - accuracy: 0.8101 - val_loss: 2.2851 - val_accuracy: 0.4299\n",
            "Epoch 13/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.4984 - accuracy: 0.8186 - val_loss: 1.2950 - val_accuracy: 0.6128\n",
            "Epoch 14/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.4359 - accuracy: 0.8561 - val_loss: 1.3175 - val_accuracy: 0.6485\n",
            "Epoch 15/50\n",
            "428/428 [==============================] - 22s 52ms/step - loss: 0.3915 - accuracy: 0.8690 - val_loss: 1.8532 - val_accuracy: 0.5954\n",
            "Epoch 16/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.3287 - accuracy: 0.8900 - val_loss: 1.5430 - val_accuracy: 0.6279\n",
            "Epoch 17/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.3371 - accuracy: 0.8779 - val_loss: 1.6270 - val_accuracy: 0.6065\n",
            "Epoch 18/50\n",
            "428/428 [==============================] - 24s 55ms/step - loss: 0.3393 - accuracy: 0.8779 - val_loss: 1.8712 - val_accuracy: 0.5321\n",
            "Epoch 19/50\n",
            "428/428 [==============================] - 24s 56ms/step - loss: 0.3025 - accuracy: 0.8892 - val_loss: 1.5377 - val_accuracy: 0.6168\n",
            "Epoch 20/50\n",
            "428/428 [==============================] - 24s 56ms/step - loss: 0.3150 - accuracy: 0.8896 - val_loss: 1.5565 - val_accuracy: 0.6643\n",
            "Epoch 21/50\n",
            "428/428 [==============================] - 25s 60ms/step - loss: 0.2376 - accuracy: 0.9204 - val_loss: 1.4817 - val_accuracy: 0.6635\n",
            "Epoch 22/50\n",
            "428/428 [==============================] - 23s 55ms/step - loss: 0.2544 - accuracy: 0.9080 - val_loss: 1.6278 - val_accuracy: 0.6366\n",
            "Epoch 23/50\n",
            "428/428 [==============================] - 23s 54ms/step - loss: 0.2742 - accuracy: 0.9013 - val_loss: 1.3404 - val_accuracy: 0.6778\n",
            "Epoch 24/50\n",
            "428/428 [==============================] - 24s 56ms/step - loss: 0.2376 - accuracy: 0.9197 - val_loss: 1.7307 - val_accuracy: 0.6437\n",
            "Epoch 25/50\n",
            "428/428 [==============================] - 24s 55ms/step - loss: 0.2981 - accuracy: 0.9048 - val_loss: 1.7292 - val_accuracy: 0.6136\n",
            "Epoch 26/50\n",
            "428/428 [==============================] - 23s 54ms/step - loss: 0.2642 - accuracy: 0.9037 - val_loss: 1.6988 - val_accuracy: 0.6263\n",
            "Epoch 27/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.2599 - accuracy: 0.9130 - val_loss: 2.1086 - val_accuracy: 0.5978\n",
            "Epoch 28/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.2440 - accuracy: 0.9165 - val_loss: 1.4427 - val_accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "428/428 [==============================] - 23s 54ms/step - loss: 0.1850 - accuracy: 0.9380 - val_loss: 1.5177 - val_accuracy: 0.6849\n",
            "Epoch 30/50\n",
            "428/428 [==============================] - 25s 58ms/step - loss: 0.1692 - accuracy: 0.9427 - val_loss: 1.6390 - val_accuracy: 0.6643\n",
            "Epoch 31/50\n",
            "428/428 [==============================] - 25s 58ms/step - loss: 0.2021 - accuracy: 0.9329 - val_loss: 4.1989 - val_accuracy: 0.4014\n",
            "Epoch 32/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 0.2037 - accuracy: 0.9353 - val_loss: 2.6049 - val_accuracy: 0.5796\n",
            "Epoch 33/50\n",
            "428/428 [==============================] - 23s 54ms/step - loss: 0.2784 - accuracy: 0.9052 - val_loss: 4.2481 - val_accuracy: 0.5004\n",
            "Epoch 34/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.3216 - accuracy: 0.8916 - val_loss: 1.9371 - val_accuracy: 0.5962\n",
            "Epoch 35/50\n",
            "428/428 [==============================] - 25s 59ms/step - loss: 0.2485 - accuracy: 0.9224 - val_loss: 1.6737 - val_accuracy: 0.6492\n",
            "Epoch 36/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.2061 - accuracy: 0.9298 - val_loss: 2.3998 - val_accuracy: 0.6176\n",
            "Epoch 37/50\n",
            "428/428 [==============================] - 23s 55ms/step - loss: 0.3537 - accuracy: 0.8873 - val_loss: 2.0862 - val_accuracy: 0.6207\n",
            "Epoch 38/50\n",
            "428/428 [==============================] - 23s 54ms/step - loss: 0.2766 - accuracy: 0.9060 - val_loss: 1.7170 - val_accuracy: 0.6334\n",
            "Epoch 39/50\n",
            "428/428 [==============================] - 24s 56ms/step - loss: 0.2282 - accuracy: 0.9224 - val_loss: 1.8108 - val_accuracy: 0.6310\n",
            "Epoch 40/50\n",
            "428/428 [==============================] - 23s 53ms/step - loss: 0.1968 - accuracy: 0.9278 - val_loss: 2.1975 - val_accuracy: 0.5764\n",
            "Epoch 41/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.2914 - accuracy: 0.9068 - val_loss: 2.0264 - val_accuracy: 0.6128\n",
            "Epoch 42/50\n",
            "428/428 [==============================] - 25s 58ms/step - loss: 0.1855 - accuracy: 0.9392 - val_loss: 1.8009 - val_accuracy: 0.6255\n",
            "Epoch 43/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 0.1717 - accuracy: 0.9423 - val_loss: 1.7667 - val_accuracy: 0.6469\n",
            "Epoch 44/50\n",
            "428/428 [==============================] - 23s 54ms/step - loss: 0.1841 - accuracy: 0.9419 - val_loss: 1.7472 - val_accuracy: 0.6540\n",
            "Epoch 45/50\n",
            "428/428 [==============================] - 24s 56ms/step - loss: 0.1536 - accuracy: 0.9446 - val_loss: 1.6472 - val_accuracy: 0.6421\n",
            "Epoch 46/50\n",
            "428/428 [==============================] - 25s 58ms/step - loss: 0.1896 - accuracy: 0.9337 - val_loss: 2.1350 - val_accuracy: 0.5534\n",
            "Epoch 47/50\n",
            "428/428 [==============================] - 24s 57ms/step - loss: 0.1820 - accuracy: 0.9356 - val_loss: 1.9903 - val_accuracy: 0.6033\n",
            "Epoch 48/50\n",
            "428/428 [==============================] - 24s 55ms/step - loss: 0.2394 - accuracy: 0.9236 - val_loss: 1.8207 - val_accuracy: 0.6461\n",
            "Epoch 49/50\n",
            "428/428 [==============================] - 25s 58ms/step - loss: 0.1628 - accuracy: 0.9431 - val_loss: 1.7750 - val_accuracy: 0.6540\n",
            "Epoch 50/50\n",
            "428/428 [==============================] - 25s 59ms/step - loss: 0.1307 - accuracy: 0.9555 - val_loss: 2.3155 - val_accuracy: 0.5867\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 2.3155 - accuracy: 0.5867\n",
            "Test accuracy: 0.5866983532905579\n",
            "40/40 [==============================] - 2s 36ms/step\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.47      0.49      0.48       180\n",
            "        Petra       0.46      0.80      0.59       188\n",
            "Roman_Theater       0.77      0.67      0.72       181\n",
            "     Wadi_Rum       0.58      0.85      0.69       188\n",
            "       jarash       0.69      0.47      0.56       256\n",
            "      um_qais       0.71      0.38      0.50       270\n",
            "\n",
            "     accuracy                           0.59      1263\n",
            "    macro avg       0.61      0.61      0.59      1263\n",
            " weighted avg       0.62      0.59      0.58      1263\n",
            "\n",
            "Epoch 1/50\n",
            "428/428 [==============================] - 30s 64ms/step - loss: 1.6958 - accuracy: 0.4181 - val_loss: 1.7186 - val_accuracy: 0.4299\n",
            "Epoch 2/50\n",
            "428/428 [==============================] - 27s 62ms/step - loss: 1.3759 - accuracy: 0.4821 - val_loss: 1.4081 - val_accuracy: 0.5194\n",
            "Epoch 3/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 1.2412 - accuracy: 0.5281 - val_loss: 1.6644 - val_accuracy: 0.4418\n",
            "Epoch 4/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 1.2820 - accuracy: 0.5031 - val_loss: 1.2609 - val_accuracy: 0.5622\n",
            "Epoch 5/50\n",
            "428/428 [==============================] - 28s 65ms/step - loss: 1.2552 - accuracy: 0.5226 - val_loss: 2.1542 - val_accuracy: 0.3674\n",
            "Epoch 6/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 1.2426 - accuracy: 0.5254 - val_loss: 1.2118 - val_accuracy: 0.5701\n",
            "Epoch 7/50\n",
            "428/428 [==============================] - 28s 64ms/step - loss: 1.1710 - accuracy: 0.5554 - val_loss: 1.0808 - val_accuracy: 0.6025\n",
            "Epoch 8/50\n",
            "428/428 [==============================] - 25s 59ms/step - loss: 1.1778 - accuracy: 0.5445 - val_loss: 1.0231 - val_accuracy: 0.6271\n",
            "Epoch 9/50\n",
            "428/428 [==============================] - 28s 66ms/step - loss: 1.1292 - accuracy: 0.5655 - val_loss: 1.1331 - val_accuracy: 0.5875\n",
            "Epoch 10/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 1.1040 - accuracy: 0.5796 - val_loss: 1.0335 - val_accuracy: 0.6247\n",
            "Epoch 11/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 1.1043 - accuracy: 0.5842 - val_loss: 1.5434 - val_accuracy: 0.5337\n",
            "Epoch 12/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 1.0711 - accuracy: 0.5963 - val_loss: 1.3095 - val_accuracy: 0.5313\n",
            "Epoch 13/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 1.0505 - accuracy: 0.5998 - val_loss: 1.0331 - val_accuracy: 0.6160\n",
            "Epoch 14/50\n",
            "428/428 [==============================] - 37s 86ms/step - loss: 1.0915 - accuracy: 0.5874 - val_loss: 1.0562 - val_accuracy: 0.6065\n",
            "Epoch 15/50\n",
            "428/428 [==============================] - 28s 65ms/step - loss: 1.0404 - accuracy: 0.6041 - val_loss: 0.8864 - val_accuracy: 0.6659\n",
            "Epoch 16/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 1.0646 - accuracy: 0.5885 - val_loss: 0.9785 - val_accuracy: 0.6200\n",
            "Epoch 17/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 1.0253 - accuracy: 0.6115 - val_loss: 1.2968 - val_accuracy: 0.5558\n",
            "Epoch 18/50\n",
            "428/428 [==============================] - 28s 65ms/step - loss: 1.0314 - accuracy: 0.6018 - val_loss: 1.0110 - val_accuracy: 0.6326\n",
            "Epoch 19/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 1.0543 - accuracy: 0.6151 - val_loss: 0.9080 - val_accuracy: 0.6524\n",
            "Epoch 20/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 1.0249 - accuracy: 0.6143 - val_loss: 1.2796 - val_accuracy: 0.5321\n",
            "Epoch 21/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 1.0121 - accuracy: 0.6143 - val_loss: 0.9299 - val_accuracy: 0.6595\n",
            "Epoch 22/50\n",
            "428/428 [==============================] - 25s 59ms/step - loss: 0.9814 - accuracy: 0.6330 - val_loss: 0.8087 - val_accuracy: 0.6857\n",
            "Epoch 23/50\n",
            "428/428 [==============================] - 25s 59ms/step - loss: 1.0026 - accuracy: 0.6201 - val_loss: 0.8580 - val_accuracy: 0.6920\n",
            "Epoch 24/50\n",
            "428/428 [==============================] - 26s 62ms/step - loss: 0.9970 - accuracy: 0.6221 - val_loss: 1.3632 - val_accuracy: 0.5598\n",
            "Epoch 25/50\n",
            "428/428 [==============================] - 24s 56ms/step - loss: 1.0032 - accuracy: 0.6392 - val_loss: 1.0498 - val_accuracy: 0.6184\n",
            "Epoch 26/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 0.9868 - accuracy: 0.6264 - val_loss: 0.9898 - val_accuracy: 0.6382\n",
            "Epoch 27/50\n",
            "428/428 [==============================] - 25s 58ms/step - loss: 0.9509 - accuracy: 0.6424 - val_loss: 0.8435 - val_accuracy: 0.6809\n",
            "Epoch 28/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.8968 - accuracy: 0.6615 - val_loss: 1.0463 - val_accuracy: 0.6461\n",
            "Epoch 29/50\n",
            "428/428 [==============================] - 25s 60ms/step - loss: 0.9830 - accuracy: 0.6229 - val_loss: 1.3274 - val_accuracy: 0.5534\n",
            "Epoch 30/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 0.9564 - accuracy: 0.6369 - val_loss: 0.8693 - val_accuracy: 0.6841\n",
            "Epoch 31/50\n",
            "428/428 [==============================] - 26s 62ms/step - loss: 0.9411 - accuracy: 0.6381 - val_loss: 0.9342 - val_accuracy: 0.6437\n",
            "Epoch 32/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 0.9176 - accuracy: 0.6607 - val_loss: 1.2417 - val_accuracy: 0.6200\n",
            "Epoch 33/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 0.9128 - accuracy: 0.6560 - val_loss: 0.8041 - val_accuracy: 0.6936\n",
            "Epoch 34/50\n",
            "428/428 [==============================] - 27s 62ms/step - loss: 0.8952 - accuracy: 0.6665 - val_loss: 0.8546 - val_accuracy: 0.6983\n",
            "Epoch 35/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 0.9421 - accuracy: 0.6576 - val_loss: 0.8206 - val_accuracy: 0.6991\n",
            "Epoch 36/50\n",
            "428/428 [==============================] - 28s 66ms/step - loss: 0.8817 - accuracy: 0.6661 - val_loss: 1.3791 - val_accuracy: 0.5344\n",
            "Epoch 37/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 0.9070 - accuracy: 0.6556 - val_loss: 0.9917 - val_accuracy: 0.6556\n",
            "Epoch 38/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 0.8836 - accuracy: 0.6739 - val_loss: 1.0304 - val_accuracy: 0.6524\n",
            "Epoch 39/50\n",
            "428/428 [==============================] - 25s 59ms/step - loss: 0.9200 - accuracy: 0.6580 - val_loss: 0.8786 - val_accuracy: 0.6738\n",
            "Epoch 40/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.8809 - accuracy: 0.6700 - val_loss: 1.2508 - val_accuracy: 0.5637\n",
            "Epoch 41/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.8730 - accuracy: 0.6790 - val_loss: 1.2866 - val_accuracy: 0.6049\n",
            "Epoch 42/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.9099 - accuracy: 0.6622 - val_loss: 0.8124 - val_accuracy: 0.6857\n",
            "Epoch 43/50\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 0.8729 - accuracy: 0.6786 - val_loss: 0.7747 - val_accuracy: 0.7189\n",
            "Epoch 44/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.8941 - accuracy: 0.6700 - val_loss: 0.7958 - val_accuracy: 0.7150\n",
            "Epoch 45/50\n",
            "428/428 [==============================] - 26s 61ms/step - loss: 0.8770 - accuracy: 0.6736 - val_loss: 0.7522 - val_accuracy: 0.7284\n",
            "Epoch 46/50\n",
            "428/428 [==============================] - 25s 58ms/step - loss: 0.8250 - accuracy: 0.6860 - val_loss: 1.0568 - val_accuracy: 0.6152\n",
            "Epoch 47/50\n",
            "428/428 [==============================] - 26s 62ms/step - loss: 0.8536 - accuracy: 0.6782 - val_loss: 0.7859 - val_accuracy: 0.7189\n",
            "Epoch 48/50\n",
            "428/428 [==============================] - 27s 64ms/step - loss: 0.8629 - accuracy: 0.6880 - val_loss: 0.9103 - val_accuracy: 0.6968\n",
            "Epoch 49/50\n",
            "428/428 [==============================] - 26s 60ms/step - loss: 0.8436 - accuracy: 0.6786 - val_loss: 0.7769 - val_accuracy: 0.7213\n",
            "Epoch 50/50\n",
            "428/428 [==============================] - 31s 72ms/step - loss: 0.8425 - accuracy: 0.6919 - val_loss: 0.9882 - val_accuracy: 0.6651\n",
            "40/40 [==============================] - 3s 61ms/step - loss: 0.9882 - accuracy: 0.6651\n",
            "Test accuracy: 0.665083110332489\n",
            "40/40 [==============================] - 3s 62ms/step\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.49      0.59      0.54       180\n",
            "        Petra       0.57      0.87      0.69       188\n",
            "Roman_Theater       0.80      0.67      0.73       181\n",
            "     Wadi_Rum       0.91      0.79      0.84       188\n",
            "       jarash       0.76      0.62      0.68       256\n",
            "      um_qais       0.60      0.53      0.56       270\n",
            "\n",
            "     accuracy                           0.67      1263\n",
            "    macro avg       0.69      0.68      0.67      1263\n",
            " weighted avg       0.69      0.67      0.67      1263\n",
            "\n"
          ]
        }
      ]
    }
  ]
}