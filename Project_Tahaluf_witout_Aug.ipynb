{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XgTGi4KGpLL",
        "outputId": "226d9803-3221-4adc-bd06-15fbd91fdd01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_docs in /usr/local/lib/python3.10/dist-packages (2023.5.24.56664)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (1.4.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (0.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (3.1.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (5.9.2)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow_docs) (2.1.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (5.7.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (0.17.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow_docs) (4.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PxrD0QzlBwVG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, Softmax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications import InceptionV3, EfficientNetB0, ResNet50, VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_input_inception\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_input_efficientnet\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\n",
        "import tensorflow as tf\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images based on the chosen model\n",
        "def preprocess_images(X, model_name):\n",
        "    if model_name == 'InceptionV3':\n",
        "        return preprocess_input_inception(X)\n",
        "    elif model_name == 'EfficientNet':\n",
        "        return preprocess_input_efficientnet(X)\n",
        "    elif model_name == 'ResNet':\n",
        "        return preprocess_input_resnet(X)\n",
        "    elif model_name == 'VGG16':\n",
        "        return preprocess_input_vgg(X)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "# Function to build a specified pre-trained model\n",
        "def build_pretrained_model(model_name, input_shape, num_classes):\n",
        "    if model_name == 'EfficientNet':\n",
        "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif model_name == 'InceptionV3':\n",
        "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif model_name == 'ResNet':\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif model_name == 'VGG16':\n",
        "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "    # Add custom dense layers on top of the pre-trained base\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(63, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to plot the model history\n",
        "def plot_model_history(model_history, metric, plot_name):\n",
        "    sns.set(style='darkgrid')  # Use Seaborn directly to set the style\n",
        "    plotter = tfdocs.plots.HistoryPlotter()\n",
        "    plotter.plot({'Model': model_history}, metric=metric)\n",
        "    plt.title(f'{metric.upper()}')\n",
        "    plt.ylim([0, 1])\n",
        "    plt.savefig(f'{plot_name}.png')\n",
        "    plt.close()\n",
        "\n",
        "# Function to load and preprocess image paths\n",
        "def load_image_paths(drive_folder_path, image_types=('*.jpg', '*.png', '*.jpeg', '*.gif')):\n",
        "    image_paths = []\n",
        "    classes = []\n",
        "\n",
        "    # Get the list of subfolders inside the main folder\n",
        "    subfolders = [f.path for f in os.scandir(drive_folder_path) if f.is_dir()]\n",
        "\n",
        "    for folder in subfolders:\n",
        "        class_name = os.path.basename(folder)  # Get the name of the folder as the class\n",
        "        class_images = []\n",
        "\n",
        "        # Iterate over specified image types\n",
        "        for image_type in image_types:\n",
        "            class_images.extend(glob(os.path.join(folder, image_type)))\n",
        "\n",
        "        image_paths.extend(class_images)\n",
        "        classes.extend([class_name] * len(class_images))\n",
        "\n",
        "    return image_paths, classes\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_images_and_labels(image_paths, target_size=(256,256)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = load_img(image_path, target_size=target_size)\n",
        "        image = img_to_array(image)\n",
        "\n",
        "        label = image_path.split(os.path.sep)[-2]\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "t3oQKxYaB80S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function for training and evaluating pre-trained models with fine-tuning\n",
        "def main_with_fine_tuning():\n",
        "    SEED = 999\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # Load the dataset into memory, normalizing the images and one-hot encoding the labels\n",
        "    drive_folder_path = '/content/drive/MyDrive/Archaeological_Sites_Classification'  # Update with your actual folder path\n",
        "    image_paths, classes = load_image_paths(drive_folder_path)\n",
        "    X, y = load_images_and_labels(image_paths)\n",
        "    X = X.astype('float') / 255.0\n",
        "    label_binarizer = LabelBinarizer()\n",
        "    y = label_binarizer.fit_transform(classes)\n",
        "\n",
        "    # Display class distribution\n",
        "    class_df = pd.DataFrame({'Class': classes})\n",
        "    print(class_df['Class'].value_counts())\n",
        "\n",
        "    (X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "    print(f'Shape of X_train: {X_train.shape}')\n",
        "    print(f'Shape of X_test: {X_test.shape}')\n",
        "    print(f'Shape of y_train: {y_train.shape}')\n",
        "    print(f'Shape of y_test: {y_test.shape}')\n",
        "\n",
        "    EPOCHS = 30\n",
        "    BATCH_SIZE = 64\n",
        "\n",
        "    # List of pre-trained models to evaluate\n",
        "    pretrained_models = ['InceptionV3', 'EfficientNet', 'ResNet', 'VGG16']\n",
        "\n",
        "    for model_name in pretrained_models:\n",
        "        print(f\"\\nTraining and evaluating {model_name} with fine-tuning...\\n\")\n",
        "\n",
        "        # Build and compile the pre-trained model\n",
        "        base_model = build_pretrained_model(model_name, (256, 256, 3), len(label_binarizer.classes_))\n",
        "        base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Fine-tune the pre-trained model\n",
        "        for layer in base_model.layers[:-5]:  # Unfreeze last few layers for fine-tuning\n",
        "            layer.trainable = True\n",
        "\n",
        "        base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # # Apply data augmentation during training\n",
        "        # if model_name == 'EfficientNet':\n",
        "        #     train_datagen = ImageDataGenerator(\n",
        "        #         preprocessing_function=preprocess_input_efficientnet,\n",
        "        #         horizontal_flip=True,\n",
        "        #         rotation_range=30,\n",
        "        #         width_shift_range=0.1,\n",
        "        #         height_shift_range=0.1,\n",
        "        #         shear_range=0.2,\n",
        "        #         zoom_range=0.2,\n",
        "        #         fill_mode='nearest'\n",
        "        #     )\n",
        "        # else:\n",
        "        #     train_datagen = ImageDataGenerator(\n",
        "        #         preprocessing_function=lambda x: preprocess_images(x, model_name),\n",
        "        #         horizontal_flip=True,\n",
        "        #         rotation_range=30,\n",
        "        #         width_shift_range=0.1,\n",
        "        #         height_shift_range=0.1,\n",
        "        #         shear_range=0.2,\n",
        "        #         zoom_range=0.2,\n",
        "        #         fill_mode='nearest'\n",
        "        #     )\n",
        "\n",
        "        # train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "        # Train the model with fine-tuning and data augmentation\n",
        "        history = base_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=EPOCHS)\n",
        "\n",
        "        # Evaluate the model\n",
        "        result = base_model.evaluate(X_test, y_test)\n",
        "        print(f'Test accuracy ({model_name} with fine-tuning): {result[1]}')\n",
        "\n",
        "        # Print classification report\n",
        "        y_pred = base_model.predict(X_test)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "        y_true_classes = np.argmax(y_test, axis=1)\n",
        "        print(f'\\nClassification Report ({model_name} with fine-tuning):\\n')\n",
        "        print(classification_report(y_true_classes, y_pred_classes, target_names=label_binarizer.classes_))\n",
        "\n",
        "        # Plot learning curve\n",
        "        plot_model_history(history, 'accuracy', f'{model_name}_learning_curve_fine_tuned')\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    main_with_fine_tuning()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-0vaVd6B9jJ",
        "outputId": "a8d540f7-6df4-4771-c26c-752151f316ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "um_qais          810\n",
            "jarash           703\n",
            "Wadi_Rum         614\n",
            "Petra            607\n",
            "Ajloun           572\n",
            "Roman_Theater    520\n",
            "Name: Class, dtype: int64\n",
            "Shape of X_train: (3060, 256, 256, 3)\n",
            "Shape of X_test: (766, 256, 256, 3)\n",
            "Shape of y_train: (3060, 6)\n",
            "Shape of y_test: (766, 6)\n",
            "\n",
            "Training and evaluating InceptionV3 with fine-tuning...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n",
            "Epoch 1/30\n",
            "96/96 [==============================] - 86s 445ms/step - loss: 0.7084 - accuracy: 0.7454 - val_loss: 0.3496 - val_accuracy: 0.8838\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 31s 323ms/step - loss: 0.1791 - accuracy: 0.9477 - val_loss: 0.2086 - val_accuracy: 0.9269\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 33s 339ms/step - loss: 0.0696 - accuracy: 0.9810 - val_loss: 0.1962 - val_accuracy: 0.9478\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 0.2577 - val_accuracy: 0.9125\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0640 - accuracy: 0.9784 - val_loss: 0.2681 - val_accuracy: 0.9230\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 32s 333ms/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 0.2834 - val_accuracy: 0.9191\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.3200 - val_accuracy: 0.9256\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 32s 332ms/step - loss: 0.0402 - accuracy: 0.9866 - val_loss: 0.3364 - val_accuracy: 0.9204\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0501 - accuracy: 0.9830 - val_loss: 0.2948 - val_accuracy: 0.9373\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.2831 - val_accuracy: 0.9269\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0454 - accuracy: 0.9859 - val_loss: 0.3677 - val_accuracy: 0.9164\n",
            "Epoch 12/30\n",
            "96/96 [==============================] - 32s 332ms/step - loss: 0.0403 - accuracy: 0.9882 - val_loss: 0.3467 - val_accuracy: 0.9308\n",
            "Epoch 13/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0488 - accuracy: 0.9833 - val_loss: 0.3139 - val_accuracy: 0.9204\n",
            "Epoch 14/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0350 - accuracy: 0.9869 - val_loss: 0.2853 - val_accuracy: 0.9360\n",
            "Epoch 15/30\n",
            "96/96 [==============================] - 32s 332ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.2664 - val_accuracy: 0.9360\n",
            "Epoch 16/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0274 - accuracy: 0.9902 - val_loss: 0.2814 - val_accuracy: 0.9543\n",
            "Epoch 17/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.2539 - val_accuracy: 0.9478\n",
            "Epoch 18/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0383 - accuracy: 0.9905 - val_loss: 0.2728 - val_accuracy: 0.9399\n",
            "Epoch 19/30\n",
            "96/96 [==============================] - 32s 332ms/step - loss: 0.0389 - accuracy: 0.9863 - val_loss: 0.2606 - val_accuracy: 0.9373\n",
            "Epoch 20/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.3348 - val_accuracy: 0.9295\n",
            "Epoch 21/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 0.2972 - val_accuracy: 0.9295\n",
            "Epoch 22/30\n",
            "96/96 [==============================] - 32s 332ms/step - loss: 0.0435 - accuracy: 0.9859 - val_loss: 0.2596 - val_accuracy: 0.9465\n",
            "Epoch 23/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.3687 - val_accuracy: 0.9243\n",
            "Epoch 24/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.2394 - val_accuracy: 0.9517\n",
            "Epoch 25/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.3555 - val_accuracy: 0.9178\n",
            "Epoch 26/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.2649 - val_accuracy: 0.9465\n",
            "Epoch 27/30\n",
            "96/96 [==============================] - 32s 331ms/step - loss: 0.0211 - accuracy: 0.9895 - val_loss: 0.2876 - val_accuracy: 0.9426\n",
            "Epoch 28/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0221 - accuracy: 0.9905 - val_loss: 0.2400 - val_accuracy: 0.9426\n",
            "Epoch 29/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.2344 - val_accuracy: 0.9504\n",
            "Epoch 30/30\n",
            "96/96 [==============================] - 32s 330ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.2642 - val_accuracy: 0.9491\n",
            "24/24 [==============================] - 2s 90ms/step - loss: 0.2642 - accuracy: 0.9491\n",
            "Test accuracy (InceptionV3 with fine-tuning): 0.9490861892700195\n",
            "24/24 [==============================] - 3s 89ms/step\n",
            "\n",
            "Classification Report (InceptionV3 with fine-tuning):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.94      0.87      0.90       118\n",
            "        Petra       0.95      0.97      0.96       120\n",
            "Roman_Theater       0.99      0.98      0.99       115\n",
            "     Wadi_Rum       0.97      0.97      0.97       125\n",
            "       jarash       0.93      0.93      0.93       139\n",
            "      um_qais       0.92      0.97      0.95       149\n",
            "\n",
            "     accuracy                           0.95       766\n",
            "    macro avg       0.95      0.95      0.95       766\n",
            " weighted avg       0.95      0.95      0.95       766\n",
            "\n",
            "\n",
            "Training and evaluating EfficientNet with fine-tuning...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 2s 0us/step\n",
            "Epoch 1/30\n",
            "96/96 [==============================] - 74s 415ms/step - loss: 1.1828 - accuracy: 0.5958 - val_loss: 1.7947 - val_accuracy: 0.1593\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 33s 344ms/step - loss: 0.4631 - accuracy: 0.8461 - val_loss: 1.7874 - val_accuracy: 0.2023\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.2683 - accuracy: 0.9212 - val_loss: 1.7973 - val_accuracy: 0.2219\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.1607 - accuracy: 0.9471 - val_loss: 1.5910 - val_accuracy: 0.4204\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.1103 - accuracy: 0.9650 - val_loss: 1.2783 - val_accuracy: 0.5287\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0872 - accuracy: 0.9778 - val_loss: 1.2037 - val_accuracy: 0.5587\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 33s 346ms/step - loss: 0.0618 - accuracy: 0.9817 - val_loss: 1.4952 - val_accuracy: 0.4178\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 33s 344ms/step - loss: 0.0474 - accuracy: 0.9866 - val_loss: 0.7111 - val_accuracy: 0.7676\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0442 - accuracy: 0.9873 - val_loss: 1.0643 - val_accuracy: 0.6514\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0381 - accuracy: 0.9895 - val_loss: 1.9815 - val_accuracy: 0.2559\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 33s 346ms/step - loss: 0.0287 - accuracy: 0.9931 - val_loss: 0.4684 - val_accuracy: 0.8551\n",
            "Epoch 12/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 2.2328 - val_accuracy: 0.3499\n",
            "Epoch 13/30\n",
            "96/96 [==============================] - 33s 346ms/step - loss: 0.0360 - accuracy: 0.9899 - val_loss: 1.5900 - val_accuracy: 0.4830\n",
            "Epoch 14/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 1.0898 - val_accuracy: 0.6410\n",
            "Epoch 15/30\n",
            "96/96 [==============================] - 33s 344ms/step - loss: 0.0222 - accuracy: 0.9918 - val_loss: 2.6013 - val_accuracy: 0.3616\n",
            "Epoch 16/30\n",
            "96/96 [==============================] - 33s 346ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 1.9725 - val_accuracy: 0.2702\n",
            "Epoch 17/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0143 - accuracy: 0.9948 - val_loss: 0.8023 - val_accuracy: 0.7572\n",
            "Epoch 18/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 2.0111 - val_accuracy: 0.5535\n",
            "Epoch 19/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 2.9281 - val_accuracy: 0.2794\n",
            "Epoch 20/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 1.8231 - val_accuracy: 0.5470\n",
            "Epoch 21/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 2.3641 - val_accuracy: 0.2937\n",
            "Epoch 22/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 2.4286 - val_accuracy: 0.3316\n",
            "Epoch 23/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 5.4303 - val_accuracy: 0.1971\n",
            "Epoch 24/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0162 - accuracy: 0.9958 - val_loss: 1.1266 - val_accuracy: 0.6867\n",
            "Epoch 25/30\n",
            "96/96 [==============================] - 33s 346ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.8197 - val_accuracy: 0.7441\n",
            "Epoch 26/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 3.7849 - val_accuracy: 0.1945\n",
            "Epoch 27/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.7809 - val_accuracy: 0.7768\n",
            "Epoch 28/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0144 - accuracy: 0.9948 - val_loss: 2.4059 - val_accuracy: 0.3225\n",
            "Epoch 29/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0145 - accuracy: 0.9938 - val_loss: 1.0638 - val_accuracy: 0.6815\n",
            "Epoch 30/30\n",
            "96/96 [==============================] - 33s 345ms/step - loss: 0.0170 - accuracy: 0.9928 - val_loss: 3.7634 - val_accuracy: 0.2924\n",
            "24/24 [==============================] - 2s 75ms/step - loss: 3.7634 - accuracy: 0.2924\n",
            "Test accuracy (EfficientNet with fine-tuning): 0.292428195476532\n",
            "24/24 [==============================] - 3s 73ms/step\n",
            "\n",
            "Classification Report (EfficientNet with fine-tuning):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.48      0.12      0.19       118\n",
            "        Petra       0.86      0.15      0.26       120\n",
            "Roman_Theater       0.60      0.10      0.18       115\n",
            "     Wadi_Rum       0.89      0.13      0.22       125\n",
            "       jarash       0.94      0.11      0.19       139\n",
            "      um_qais       0.23      1.00      0.37       149\n",
            "\n",
            "     accuracy                           0.29       766\n",
            "    macro avg       0.67      0.27      0.23       766\n",
            " weighted avg       0.66      0.29      0.24       766\n",
            "\n",
            "\n",
            "Training and evaluating ResNet with fine-tuning...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n",
            "Epoch 1/30\n",
            "96/96 [==============================] - 83s 517ms/step - loss: 0.6124 - accuracy: 0.7846 - val_loss: 2.4132 - val_accuracy: 0.1540\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 39s 408ms/step - loss: 0.1327 - accuracy: 0.9552 - val_loss: 4.0873 - val_accuracy: 0.1540\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 40s 413ms/step - loss: 0.0811 - accuracy: 0.9748 - val_loss: 3.6430 - val_accuracy: 0.1841\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 39s 411ms/step - loss: 0.0511 - accuracy: 0.9846 - val_loss: 4.6088 - val_accuracy: 0.1540\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 39s 412ms/step - loss: 0.0624 - accuracy: 0.9807 - val_loss: 2.3738 - val_accuracy: 0.2520\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0698 - accuracy: 0.9791 - val_loss: 2.8605 - val_accuracy: 0.3055\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0585 - accuracy: 0.9807 - val_loss: 2.0969 - val_accuracy: 0.4321\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 39s 412ms/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 1.2368 - val_accuracy: 0.6710\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0461 - accuracy: 0.9859 - val_loss: 1.1309 - val_accuracy: 0.7298\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0353 - accuracy: 0.9902 - val_loss: 0.5279 - val_accuracy: 0.8695\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 39s 412ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.2522 - val_accuracy: 0.9256\n",
            "Epoch 12/30\n",
            "96/96 [==============================] - 39s 412ms/step - loss: 0.0475 - accuracy: 0.9879 - val_loss: 0.3219 - val_accuracy: 0.9125\n",
            "Epoch 13/30\n",
            "96/96 [==============================] - 39s 411ms/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.3055 - val_accuracy: 0.9191\n",
            "Epoch 14/30\n",
            "96/96 [==============================] - 40s 413ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.2233 - val_accuracy: 0.9439\n",
            "Epoch 15/30\n",
            "96/96 [==============================] - 39s 412ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.2501 - val_accuracy: 0.9413\n",
            "Epoch 16/30\n",
            "96/96 [==============================] - 39s 411ms/step - loss: 0.0205 - accuracy: 0.9925 - val_loss: 0.3114 - val_accuracy: 0.9347\n",
            "Epoch 17/30\n",
            "96/96 [==============================] - 39s 411ms/step - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.3837 - val_accuracy: 0.9191\n",
            "Epoch 18/30\n",
            "96/96 [==============================] - 39s 410ms/step - loss: 0.0620 - accuracy: 0.9775 - val_loss: 0.2894 - val_accuracy: 0.9217\n",
            "Epoch 19/30\n",
            "96/96 [==============================] - 40s 413ms/step - loss: 0.0546 - accuracy: 0.9824 - val_loss: 0.5067 - val_accuracy: 0.8877\n",
            "Epoch 20/30\n",
            "96/96 [==============================] - 39s 411ms/step - loss: 0.0519 - accuracy: 0.9843 - val_loss: 0.3330 - val_accuracy: 0.9282\n",
            "Epoch 21/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0364 - accuracy: 0.9892 - val_loss: 0.3390 - val_accuracy: 0.9360\n",
            "Epoch 22/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.2139 - val_accuracy: 0.9491\n",
            "Epoch 23/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.2529 - val_accuracy: 0.9504\n",
            "Epoch 24/30\n",
            "96/96 [==============================] - 39s 411ms/step - loss: 0.0257 - accuracy: 0.9922 - val_loss: 0.2299 - val_accuracy: 0.9347\n",
            "Epoch 25/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.4034 - val_accuracy: 0.9138\n",
            "Epoch 26/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.3096 - val_accuracy: 0.9334\n",
            "Epoch 27/30\n",
            "96/96 [==============================] - 40s 413ms/step - loss: 0.0262 - accuracy: 0.9935 - val_loss: 0.2203 - val_accuracy: 0.9439\n",
            "Epoch 28/30\n",
            "96/96 [==============================] - 40s 413ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.1883 - val_accuracy: 0.9517\n",
            "Epoch 29/30\n",
            "96/96 [==============================] - 40s 412ms/step - loss: 0.0203 - accuracy: 0.9918 - val_loss: 0.4218 - val_accuracy: 0.8995\n",
            "Epoch 30/30\n",
            "96/96 [==============================] - 39s 412ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 0.2174 - val_accuracy: 0.9517\n",
            "24/24 [==============================] - 3s 116ms/step - loss: 0.2174 - accuracy: 0.9517\n",
            "Test accuracy (ResNet with fine-tuning): 0.9516971111297607\n",
            "24/24 [==============================] - 4s 114ms/step\n",
            "\n",
            "Classification Report (ResNet with fine-tuning):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.92      0.91      0.91       118\n",
            "        Petra       0.99      0.93      0.96       120\n",
            "Roman_Theater       0.98      0.99      0.99       115\n",
            "     Wadi_Rum       0.95      0.98      0.97       125\n",
            "       jarash       0.91      0.97      0.94       139\n",
            "      um_qais       0.96      0.93      0.94       149\n",
            "\n",
            "     accuracy                           0.95       766\n",
            "    macro avg       0.95      0.95      0.95       766\n",
            " weighted avg       0.95      0.95      0.95       766\n",
            "\n",
            "\n",
            "Training and evaluating VGG16 with fine-tuning...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n",
            "Epoch 1/30\n",
            "96/96 [==============================] - 110s 856ms/step - loss: 1.6333 - accuracy: 0.3170 - val_loss: 1.3730 - val_accuracy: 0.4700\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 55s 578ms/step - loss: 1.0868 - accuracy: 0.5895 - val_loss: 0.9337 - val_accuracy: 0.6762\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 56s 579ms/step - loss: 0.7732 - accuracy: 0.7327 - val_loss: 0.7987 - val_accuracy: 0.7585\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 56s 579ms/step - loss: 0.5854 - accuracy: 0.8013 - val_loss: 0.4225 - val_accuracy: 0.8642\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 55s 578ms/step - loss: 0.4668 - accuracy: 0.8392 - val_loss: 0.4619 - val_accuracy: 0.8277\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 55s 577ms/step - loss: 0.3578 - accuracy: 0.8761 - val_loss: 0.3263 - val_accuracy: 0.8799\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 55s 577ms/step - loss: 0.3175 - accuracy: 0.8899 - val_loss: 0.4169 - val_accuracy: 0.8590\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 55s 577ms/step - loss: 0.3181 - accuracy: 0.8993 - val_loss: 0.2756 - val_accuracy: 0.9138\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 55s 577ms/step - loss: 0.2239 - accuracy: 0.9291 - val_loss: 0.2125 - val_accuracy: 0.9269\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 56s 580ms/step - loss: 0.2206 - accuracy: 0.9255 - val_loss: 0.2748 - val_accuracy: 0.9151\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 55s 579ms/step - loss: 0.1886 - accuracy: 0.9346 - val_loss: 0.3241 - val_accuracy: 0.8799\n",
            "Epoch 12/30\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 0.1411 - accuracy: 0.9529 - val_loss: 0.3401 - val_accuracy: 0.8995\n",
            "Epoch 13/30\n",
            "96/96 [==============================] - 55s 579ms/step - loss: 0.1932 - accuracy: 0.9373 - val_loss: 0.2345 - val_accuracy: 0.9164\n",
            "Epoch 14/30\n",
            "96/96 [==============================] - 55s 578ms/step - loss: 0.1266 - accuracy: 0.9578 - val_loss: 0.2511 - val_accuracy: 0.9191\n",
            "Epoch 15/30\n",
            "96/96 [==============================] - 55s 577ms/step - loss: 0.1300 - accuracy: 0.9546 - val_loss: 0.4029 - val_accuracy: 0.8695\n",
            "Epoch 16/30\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.0709 - accuracy: 0.9781 - val_loss: 0.4943 - val_accuracy: 0.9021\n",
            "Epoch 17/30\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.1238 - accuracy: 0.9588 - val_loss: 0.2932 - val_accuracy: 0.8995\n",
            "Epoch 18/30\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.1264 - accuracy: 0.9641 - val_loss: 0.3810 - val_accuracy: 0.9073\n",
            "Epoch 19/30\n",
            "96/96 [==============================] - 55s 577ms/step - loss: 0.1545 - accuracy: 0.9520 - val_loss: 0.3326 - val_accuracy: 0.9086\n",
            "Epoch 20/30\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.3465 - val_accuracy: 0.9178\n",
            "Epoch 21/30\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 0.0835 - accuracy: 0.9778 - val_loss: 0.5000 - val_accuracy: 0.8512\n",
            "Epoch 22/30\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.1790 - accuracy: 0.9399 - val_loss: 0.3420 - val_accuracy: 0.9060\n",
            "Epoch 23/30\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 0.0711 - accuracy: 0.9804 - val_loss: 0.2941 - val_accuracy: 0.9138\n",
            "Epoch 24/30\n",
            "96/96 [==============================] - 55s 574ms/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.3186 - val_accuracy: 0.9321\n",
            "Epoch 25/30\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.0555 - accuracy: 0.9843 - val_loss: 0.2976 - val_accuracy: 0.9204\n",
            "Epoch 26/30\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 0.0665 - accuracy: 0.9788 - val_loss: 0.3101 - val_accuracy: 0.9269\n",
            "Epoch 27/30\n",
            "96/96 [==============================] - 55s 575ms/step - loss: 0.0875 - accuracy: 0.9722 - val_loss: 0.2717 - val_accuracy: 0.9178\n",
            "Epoch 28/30\n",
            "96/96 [==============================] - 55s 574ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.3472 - val_accuracy: 0.9230\n",
            "Epoch 29/30\n",
            "96/96 [==============================] - 55s 576ms/step - loss: 0.0402 - accuracy: 0.9886 - val_loss: 0.2650 - val_accuracy: 0.9399\n",
            "Epoch 30/30\n",
            "96/96 [==============================] - 55s 573ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.3299 - val_accuracy: 0.9308\n",
            "24/24 [==============================] - 4s 165ms/step - loss: 0.3299 - accuracy: 0.9308\n",
            "Test accuracy (VGG16 with fine-tuning): 0.9308093786239624\n",
            "24/24 [==============================] - 4s 164ms/step\n",
            "\n",
            "Classification Report (VGG16 with fine-tuning):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.86      0.86      0.86       118\n",
            "        Petra       0.93      0.96      0.94       120\n",
            "Roman_Theater       1.00      0.97      0.99       115\n",
            "     Wadi_Rum       0.96      0.97      0.96       125\n",
            "       jarash       0.91      0.94      0.93       139\n",
            "      um_qais       0.93      0.89      0.91       149\n",
            "\n",
            "     accuracy                           0.93       766\n",
            "    macro avg       0.93      0.93      0.93       766\n",
            " weighted avg       0.93      0.93      0.93       766\n",
            "\n"
          ]
        }
      ]
    }
  ]
}