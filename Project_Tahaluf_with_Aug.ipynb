{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XgTGi4KGpLL",
        "outputId": "a7e3fe40-23c7-4575-e178-30abab06d36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_docs in /usr/local/lib/python3.10/dist-packages (2023.5.24.56664)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (1.4.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (0.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (3.1.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (5.9.2)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow_docs) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow_docs) (2.1.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (5.7.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow_docs) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow_docs) (0.17.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow_docs) (4.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxrD0QzlBwVG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, Softmax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications import InceptionV3, EfficientNetB0, ResNet50, VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_input_inception\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_input_efficientnet\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\n",
        "import tensorflow as tf\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.models import save_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images based on the chosen model\n",
        "def pr2eprocess_images(X, model_name):\n",
        "    if model_name == 'InceptionV3':\n",
        "        return preprocess_input_inception(X)\n",
        "    elif model_name == 'EfficientNet':\n",
        "        return preprocess_input_efficientnet(X)\n",
        "    elif model_name == 'ResNet':\n",
        "        return preprocess_input_resnet(X)\n",
        "    elif model_name == 'VGG16':\n",
        "        return preprocess_input_vgg(X)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "# Function to build a specified pre-trained model\n",
        "def build_pretrained_model(model_name, input_shape, num_classes):\n",
        "    if model_name == 'EfficientNet':\n",
        "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif model_name == 'InceptionV3':\n",
        "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif model_name == 'ResNet':\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif model_name == 'VGG16':\n",
        "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "    # Add custom dense layers on top of the pre-trained base\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to plot the model history\n",
        "def plot_model_history(model_history, metric, plot_name):\n",
        "    sns.set(style='darkgrid')  # Use Seaborn directly to set the style\n",
        "    plotter = tfdocs.plots.HistoryPlotter()\n",
        "    plotter.plot({'Model': model_history}, metric=metric)\n",
        "    plt.title(f'{metric.upper()}')\n",
        "    plt.ylim([0, 1])\n",
        "    plt.savefig(f'{plot_name}.png')\n",
        "    plt.close()\n",
        "\n",
        "# Function to load and preprocess image paths\n",
        "def load_image_paths(drive_folder_path, image_types=('*.jpg', '*.png', '*.jpeg', '*.gif')):\n",
        "    image_paths = []\n",
        "    classes = []\n",
        "\n",
        "    # Get the list of subfolders inside the main folder\n",
        "    subfolders = [f.path for f in os.scandir(drive_folder_path) if f.is_dir()]\n",
        "\n",
        "    for folder in subfolders:\n",
        "        class_name = os.path.basename(folder)  # Get the name of the folder as the class\n",
        "        class_images = []\n",
        "\n",
        "        # Iterate over specified image types\n",
        "        for image_type in image_types:\n",
        "            class_images.extend(glob(os.path.join(folder, image_type)))\n",
        "\n",
        "        image_paths.extend(class_images)\n",
        "        classes.extend([class_name] * len(class_images))\n",
        "\n",
        "    return image_paths, classes\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_images_and_labels(image_paths, target_size=(256,256)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = load_img(image_path, target_size=target_size)\n",
        "        image = img_to_array(image)\n",
        "\n",
        "        label = image_path.split(os.path.sep)[-2]\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "\n",
        "        return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "2IANJfXerjdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function for training and evaluating pre-trained models with fine-tuning\n",
        "def main_with_fine_tuning():\n",
        "    SEED = 999\n",
        "    np.random.seed(SEED)\n",
        "\n",
        "    # Load the dataset into memory, normalizing the images and one-hot encoding the labels\n",
        "    drive_folder_path = '/content/drive/MyDrive/Archaeological_Sites_Classification'  # Update with your actual folder path\n",
        "    image_paths, classes = load_image_paths(drive_folder_path)\n",
        "    X, y = load_images_and_labels(image_paths)\n",
        "    X = X.astype('float') / 255.0\n",
        "    label_binarizer = LabelBinarizer()\n",
        "    y = label_binarizer.fit_transform(classes)\n",
        "\n",
        "    # Display class distribution\n",
        "    class_df = pd.DataFrame({'Class': classes})\n",
        "    print(class_df['Class'].value_counts())\n",
        "\n",
        "    (X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "    print(f'Shape of X_train: {X_train.shape}')\n",
        "    print(f'Shape of X_test: {X_test.shape}')\n",
        "    print(f'Shape of y_train: {y_train.shape}')\n",
        "    print(f'Shape of y_test: {y_test.shape}')\n",
        "\n",
        "    EPOCHS = 30\n",
        "    BATCH_SIZE = 64\n",
        "\n",
        "    pretrained_models = ['InceptionV3', 'EfficientNet', 'ResNet', 'VGG16']\n",
        "\n",
        "    for model_name in pretrained_models:\n",
        "        print(f\"\\nTraining and evaluating {model_name} with fine-tuning...\\n\")\n",
        "\n",
        "        # Build and compile the pre-trained model\n",
        "        base_model = build_pretrained_model(model_name, (256, 256, 3), len(label_binarizer.classes_))\n",
        "        base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Fine-tune the pre-trained model\n",
        "        for layer in base_model.layers[:-5]:  # Unfreeze last few layers for fine-tuning\n",
        "            layer.trainable = True\n",
        "\n",
        "        base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "                # Apply data augmentation during training\n",
        "        if model_name == 'EfficientNet':\n",
        "            train_datagen = ImageDataGenerator(\n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization=True,\n",
        "        rotation_range=20,\n",
        "        fill_mode='nearest',\n",
        "        validation_split = 0.20\n",
        "            )\n",
        "        else:\n",
        "            train_datagen = ImageDataGenerator(\n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization=True,\n",
        "        rotation_range=20,\n",
        "        fill_mode='nearest',\n",
        "        validation_split = 0.20\n",
        "            )\n",
        "\n",
        "\n",
        "        train_datagen.fit(X_train)\n",
        "\n",
        "        train_generator = train_datagen.flow(X_train, y_train, batch_size = BATCH_SIZE, subset='training')\n",
        "\n",
        "\n",
        "\n",
        "        # Train the model with fine-tuning and data augmentation\n",
        "        history = base_model.fit_generator(train_generator, validation_data=(X_test, y_test), epochs=EPOCHS)\n",
        "\n",
        "        # Evaluate the model\n",
        "        result = base_model.evaluate(X_test, y_test)\n",
        "        print(f'Test accuracy ({model_name} with fine-tuning): {result[1]}')\n",
        "\n",
        "        # Print classification report\n",
        "        y_pred = base_model.predict(X_test)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "        y_true_classes = np.argmax(y_test, axis=1)\n",
        "        print(f'\\nClassification Report ({model_name} with fine-tuning):\\n')\n",
        "        print(classification_report(y_true_classes, y_pred_classes, target_names=label_binarizer.classes_))\n",
        "        # Plot learning curve\n",
        "        plot_model_history(history, 'accuracy', f'{model_name}_learning_curve_fine_tuned')\n",
        "\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    main_with_fine_tuning()"
      ],
      "metadata": {
        "id": "F-0vaVd6B9jJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281dfddb-9eb2-477c-819b-70bb195bd1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "um_qais          763\n",
            "jarash           703\n",
            "Wadi_Rum         614\n",
            "Petra            607\n",
            "Ajloun           572\n",
            "Roman_Theater    520\n",
            "Name: Class, dtype: int64\n",
            "Shape of X_train: (3023, 256, 256, 3)\n",
            "Shape of X_test: (756, 256, 256, 3)\n",
            "Shape of y_train: (3023, 6)\n",
            "Shape of y_test: (756, 6)\n",
            "\n",
            "Training and evaluating InceptionV3 with fine-tuning...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae421316b683>:68: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = base_model.fit_generator(train_generator, validation_data=(X_test, y_test), epochs=EPOCHS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "38/38 [==============================] - 98s 1s/step - loss: 0.8306 - accuracy: 0.6978 - val_loss: 0.8059 - val_accuracy: 0.7235\n",
            "Epoch 2/30\n",
            "38/38 [==============================] - 33s 864ms/step - loss: 0.2306 - accuracy: 0.9239 - val_loss: 0.4066 - val_accuracy: 0.8452\n",
            "Epoch 3/30\n",
            "38/38 [==============================] - 33s 855ms/step - loss: 0.1022 - accuracy: 0.9686 - val_loss: 0.3344 - val_accuracy: 0.8823\n",
            "Epoch 4/30\n",
            "38/38 [==============================] - 33s 852ms/step - loss: 0.0588 - accuracy: 0.9814 - val_loss: 0.3515 - val_accuracy: 0.8902\n",
            "Epoch 5/30\n",
            "38/38 [==============================] - 33s 861ms/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 0.3123 - val_accuracy: 0.8968\n",
            "Epoch 6/30\n",
            "38/38 [==============================] - 33s 847ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.3010 - val_accuracy: 0.8915\n",
            "Epoch 7/30\n",
            "38/38 [==============================] - 34s 869ms/step - loss: 0.0312 - accuracy: 0.9884 - val_loss: 0.4254 - val_accuracy: 0.8783\n",
            "Epoch 8/30\n",
            "38/38 [==============================] - 33s 859ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.4685 - val_accuracy: 0.8849\n",
            "Epoch 9/30\n",
            "38/38 [==============================] - 33s 866ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 1.0369 - val_accuracy: 0.7765\n",
            "Epoch 10/30\n",
            "38/38 [==============================] - 32s 840ms/step - loss: 0.0273 - accuracy: 0.9888 - val_loss: 0.6204 - val_accuracy: 0.8479\n",
            "Epoch 11/30\n",
            "38/38 [==============================] - 33s 868ms/step - loss: 0.0314 - accuracy: 0.9868 - val_loss: 0.4584 - val_accuracy: 0.8796\n",
            "Epoch 12/30\n",
            "38/38 [==============================] - 33s 867ms/step - loss: 0.0230 - accuracy: 0.9905 - val_loss: 0.4652 - val_accuracy: 0.8862\n",
            "Epoch 13/30\n",
            "38/38 [==============================] - 32s 841ms/step - loss: 0.0183 - accuracy: 0.9921 - val_loss: 0.5458 - val_accuracy: 0.8730\n",
            "Epoch 14/30\n",
            "38/38 [==============================] - 34s 870ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.6253 - val_accuracy: 0.8624\n",
            "Epoch 15/30\n",
            "38/38 [==============================] - 33s 857ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.6529 - val_accuracy: 0.8413\n",
            "Epoch 16/30\n",
            "38/38 [==============================] - 34s 880ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.5775 - val_accuracy: 0.8690\n",
            "Epoch 17/30\n",
            "38/38 [==============================] - 33s 843ms/step - loss: 0.0213 - accuracy: 0.9909 - val_loss: 0.5324 - val_accuracy: 0.8810\n",
            "Epoch 18/30\n",
            "38/38 [==============================] - 32s 837ms/step - loss: 0.0171 - accuracy: 0.9955 - val_loss: 0.5303 - val_accuracy: 0.8770\n",
            "Epoch 19/30\n",
            "38/38 [==============================] - 34s 886ms/step - loss: 0.0148 - accuracy: 0.9934 - val_loss: 0.5842 - val_accuracy: 0.8770\n",
            "Epoch 20/30\n",
            "38/38 [==============================] - 34s 882ms/step - loss: 0.0252 - accuracy: 0.9930 - val_loss: 0.5700 - val_accuracy: 0.8664\n",
            "Epoch 21/30\n",
            "38/38 [==============================] - 33s 856ms/step - loss: 0.0162 - accuracy: 0.9934 - val_loss: 0.5003 - val_accuracy: 0.8902\n",
            "Epoch 22/30\n",
            "38/38 [==============================] - 33s 865ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.5794 - val_accuracy: 0.8690\n",
            "Epoch 23/30\n",
            "38/38 [==============================] - 33s 848ms/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 0.7411 - val_accuracy: 0.8439\n",
            "Epoch 24/30\n",
            "38/38 [==============================] - 33s 860ms/step - loss: 0.0219 - accuracy: 0.9901 - val_loss: 0.6358 - val_accuracy: 0.8690\n",
            "Epoch 25/30\n",
            "38/38 [==============================] - 33s 863ms/step - loss: 0.0193 - accuracy: 0.9909 - val_loss: 0.5704 - val_accuracy: 0.8717\n",
            "Epoch 26/30\n",
            "38/38 [==============================] - 32s 834ms/step - loss: 0.0117 - accuracy: 0.9950 - val_loss: 0.6344 - val_accuracy: 0.8664\n",
            "Epoch 27/30\n",
            "38/38 [==============================] - 33s 851ms/step - loss: 0.0135 - accuracy: 0.9938 - val_loss: 0.6595 - val_accuracy: 0.8611\n",
            "Epoch 28/30\n",
            "38/38 [==============================] - 34s 882ms/step - loss: 0.0147 - accuracy: 0.9938 - val_loss: 0.4551 - val_accuracy: 0.8968\n",
            "Epoch 29/30\n",
            "38/38 [==============================] - 33s 851ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.5842 - val_accuracy: 0.8743\n",
            "Epoch 30/30\n",
            "38/38 [==============================] - 32s 828ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.5031 - val_accuracy: 0.8889\n",
            "24/24 [==============================] - 2s 89ms/step - loss: 0.5031 - accuracy: 0.8889\n",
            "Test accuracy (InceptionV3 with fine-tuning): 0.8888888955116272\n",
            "24/24 [==============================] - 3s 91ms/step\n",
            "\n",
            "Classification Report (InceptionV3 with fine-tuning):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.90      0.84      0.87       120\n",
            "        Petra       0.92      0.90      0.91       118\n",
            "Roman_Theater       0.88      0.99      0.93       114\n",
            "     Wadi_Rum       0.86      0.97      0.91       129\n",
            "       jarash       0.96      0.75      0.84       126\n",
            "      um_qais       0.85      0.89      0.87       149\n",
            "\n",
            "     accuracy                           0.89       756\n",
            "    macro avg       0.89      0.89      0.89       756\n",
            " weighted avg       0.89      0.89      0.89       756\n",
            "\n",
            "\n",
            "Training and evaluating EfficientNet with fine-tuning...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae421316b683>:68: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = base_model.fit_generator(train_generator, validation_data=(X_test, y_test), epochs=EPOCHS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "38/38 [==============================] - 70s 963ms/step - loss: 1.3699 - accuracy: 0.5362 - val_loss: 1.8094 - val_accuracy: 0.1561\n",
            "Epoch 2/30\n",
            "38/38 [==============================] - 33s 864ms/step - loss: 0.5902 - accuracy: 0.8222 - val_loss: 1.7979 - val_accuracy: 0.1508\n",
            "Epoch 3/30\n",
            "38/38 [==============================] - 33s 850ms/step - loss: 0.3401 - accuracy: 0.8876 - val_loss: 1.7950 - val_accuracy: 0.1508\n",
            "Epoch 4/30\n",
            "38/38 [==============================] - 34s 873ms/step - loss: 0.2320 - accuracy: 0.9202 - val_loss: 1.7924 - val_accuracy: 0.1376\n",
            "Epoch 5/30\n",
            "38/38 [==============================] - 33s 848ms/step - loss: 0.1711 - accuracy: 0.9458 - val_loss: 1.7935 - val_accuracy: 0.1495\n",
            "Epoch 6/30\n",
            "38/38 [==============================] - 34s 871ms/step - loss: 0.1175 - accuracy: 0.9682 - val_loss: 1.8062 - val_accuracy: 0.1574\n",
            "Epoch 7/30\n",
            "38/38 [==============================] - 34s 877ms/step - loss: 0.0739 - accuracy: 0.9797 - val_loss: 1.8176 - val_accuracy: 0.2050\n",
            "Epoch 8/30\n",
            "38/38 [==============================] - 32s 817ms/step - loss: 0.0606 - accuracy: 0.9847 - val_loss: 1.8327 - val_accuracy: 0.1799\n",
            "Epoch 9/30\n",
            "38/38 [==============================] - 33s 848ms/step - loss: 0.0574 - accuracy: 0.9843 - val_loss: 2.0214 - val_accuracy: 0.2063\n",
            "Epoch 10/30\n",
            "38/38 [==============================] - 31s 806ms/step - loss: 0.0368 - accuracy: 0.9917 - val_loss: 2.1030 - val_accuracy: 0.1984\n",
            "Epoch 11/30\n",
            "38/38 [==============================] - 33s 845ms/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 2.1347 - val_accuracy: 0.2302\n",
            "Epoch 12/30\n",
            "38/38 [==============================] - 33s 847ms/step - loss: 0.0373 - accuracy: 0.9888 - val_loss: 2.5629 - val_accuracy: 0.2593\n",
            "Epoch 13/30\n",
            "38/38 [==============================] - 34s 872ms/step - loss: 0.0375 - accuracy: 0.9897 - val_loss: 2.2808 - val_accuracy: 0.2659\n",
            "Epoch 14/30\n",
            "38/38 [==============================] - 33s 848ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 2.1236 - val_accuracy: 0.3373\n",
            "Epoch 15/30\n",
            "38/38 [==============================] - 33s 858ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 2.6536 - val_accuracy: 0.3386\n",
            "Epoch 16/30\n",
            "38/38 [==============================] - 32s 832ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 2.2971 - val_accuracy: 0.4233\n",
            "Epoch 17/30\n",
            "38/38 [==============================] - 33s 843ms/step - loss: 0.0230 - accuracy: 0.9909 - val_loss: 2.6407 - val_accuracy: 0.3386\n",
            "Epoch 18/30\n",
            "38/38 [==============================] - 34s 868ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 3.4348 - val_accuracy: 0.2540\n",
            "Epoch 19/30\n",
            "38/38 [==============================] - 32s 833ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 4.0515 - val_accuracy: 0.2540\n",
            "Epoch 20/30\n",
            "38/38 [==============================] - 33s 866ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 2.3157 - val_accuracy: 0.4352\n",
            "Epoch 21/30\n",
            "38/38 [==============================] - 32s 838ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 2.0406 - val_accuracy: 0.4563\n",
            "Epoch 22/30\n",
            "38/38 [==============================] - 32s 816ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 1.2886 - val_accuracy: 0.6468\n",
            "Epoch 23/30\n",
            "38/38 [==============================] - 32s 835ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.8100 - val_accuracy: 0.7950\n",
            "Epoch 24/30\n",
            "38/38 [==============================] - 31s 808ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.7381 - val_accuracy: 0.8228\n",
            "Epoch 25/30\n",
            "38/38 [==============================] - 33s 859ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 1.4250 - val_accuracy: 0.6349\n",
            "Epoch 26/30\n",
            "38/38 [==============================] - 33s 867ms/step - loss: 0.0139 - accuracy: 0.9946 - val_loss: 3.5710 - val_accuracy: 0.2857\n",
            "Epoch 27/30\n",
            "38/38 [==============================] - 32s 831ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 1.2693 - val_accuracy: 0.6733\n",
            "Epoch 28/30\n",
            "38/38 [==============================] - 32s 816ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 2.1171 - val_accuracy: 0.4339\n",
            "Epoch 29/30\n",
            "38/38 [==============================] - 31s 793ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 3.5401 - val_accuracy: 0.2235\n",
            "Epoch 30/30\n",
            "38/38 [==============================] - 32s 829ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 3.3957 - val_accuracy: 0.2090\n",
            "24/24 [==============================] - 2s 74ms/step - loss: 3.3957 - accuracy: 0.2090\n",
            "Test accuracy (EfficientNet with fine-tuning): 0.20899471640586853\n",
            "24/24 [==============================] - 3s 73ms/step\n",
            "\n",
            "Classification Report (EfficientNet with fine-tuning):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.11      0.03      0.05       120\n",
            "        Petra       0.00      0.00      0.00       118\n",
            "Roman_Theater       0.54      0.06      0.11       114\n",
            "     Wadi_Rum       0.00      0.00      0.00       129\n",
            "       jarash       0.00      0.00      0.00       126\n",
            "      um_qais       0.21      0.99      0.34       149\n",
            "\n",
            "     accuracy                           0.21       756\n",
            "    macro avg       0.14      0.18      0.08       756\n",
            " weighted avg       0.14      0.21      0.09       756\n",
            "\n",
            "\n",
            "Training and evaluating ResNet with fine-tuning...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae421316b683>:68: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = base_model.fit_generator(train_generator, validation_data=(X_test, y_test), epochs=EPOCHS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "38/38 [==============================] - 86s 1s/step - loss: 0.7024 - accuracy: 0.7437 - val_loss: 2.8219 - val_accuracy: 0.1706\n",
            "Epoch 2/30\n",
            "38/38 [==============================] - 34s 877ms/step - loss: 0.1734 - accuracy: 0.9409 - val_loss: 3.1128 - val_accuracy: 0.1587\n",
            "Epoch 3/30\n",
            "38/38 [==============================] - 34s 889ms/step - loss: 0.0835 - accuracy: 0.9777 - val_loss: 2.5860 - val_accuracy: 0.1587\n",
            "Epoch 4/30\n",
            "38/38 [==============================] - 35s 898ms/step - loss: 0.0495 - accuracy: 0.9872 - val_loss: 2.7797 - val_accuracy: 0.1601\n",
            "Epoch 5/30\n",
            "38/38 [==============================] - 35s 902ms/step - loss: 0.0415 - accuracy: 0.9888 - val_loss: 2.4053 - val_accuracy: 0.1720\n",
            "Epoch 6/30\n",
            "38/38 [==============================] - 35s 902ms/step - loss: 0.0267 - accuracy: 0.9934 - val_loss: 3.3799 - val_accuracy: 0.1587\n",
            "Epoch 7/30\n",
            "38/38 [==============================] - 35s 898ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 2.8973 - val_accuracy: 0.1587\n",
            "Epoch 8/30\n",
            "38/38 [==============================] - 35s 898ms/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 3.3850 - val_accuracy: 0.1587\n",
            "Epoch 9/30\n",
            "38/38 [==============================] - 35s 905ms/step - loss: 0.0399 - accuracy: 0.9876 - val_loss: 3.5095 - val_accuracy: 0.1653\n",
            "Epoch 10/30\n",
            "38/38 [==============================] - 35s 901ms/step - loss: 0.0229 - accuracy: 0.9913 - val_loss: 3.9986 - val_accuracy: 0.1693\n",
            "Epoch 11/30\n",
            "38/38 [==============================] - 35s 897ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 2.7244 - val_accuracy: 0.1667\n",
            "Epoch 12/30\n",
            "38/38 [==============================] - 35s 898ms/step - loss: 0.0347 - accuracy: 0.9864 - val_loss: 2.7658 - val_accuracy: 0.1640\n",
            "Epoch 13/30\n",
            "38/38 [==============================] - 35s 901ms/step - loss: 0.0412 - accuracy: 0.9847 - val_loss: 2.1300 - val_accuracy: 0.2791\n",
            "Epoch 14/30\n",
            "38/38 [==============================] - 35s 905ms/step - loss: 0.0281 - accuracy: 0.9901 - val_loss: 2.2505 - val_accuracy: 0.3069\n",
            "Epoch 15/30\n",
            "38/38 [==============================] - 35s 901ms/step - loss: 0.0271 - accuracy: 0.9893 - val_loss: 2.1845 - val_accuracy: 0.3704\n",
            "Epoch 16/30\n",
            "38/38 [==============================] - 35s 907ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 1.8474 - val_accuracy: 0.4272\n",
            "Epoch 17/30\n",
            "38/38 [==============================] - 35s 902ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 1.6056 - val_accuracy: 0.4722\n",
            "Epoch 18/30\n",
            "38/38 [==============================] - 35s 908ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 1.6368 - val_accuracy: 0.4960\n",
            "Epoch 19/30\n",
            "38/38 [==============================] - 35s 902ms/step - loss: 0.0285 - accuracy: 0.9893 - val_loss: 1.5358 - val_accuracy: 0.5661\n",
            "Epoch 20/30\n",
            "38/38 [==============================] - 35s 900ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.9859 - val_accuracy: 0.6971\n",
            "Epoch 21/30\n",
            "38/38 [==============================] - 35s 900ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 1.0524 - val_accuracy: 0.6852\n",
            "Epoch 22/30\n",
            "38/38 [==============================] - 35s 901ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.9020 - val_accuracy: 0.7090\n",
            "Epoch 23/30\n",
            "38/38 [==============================] - 35s 900ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 1.1104 - val_accuracy: 0.6852\n",
            "Epoch 24/30\n",
            "38/38 [==============================] - 35s 900ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 1.4226 - val_accuracy: 0.6349\n",
            "Epoch 25/30\n",
            "38/38 [==============================] - 35s 899ms/step - loss: 0.0132 - accuracy: 0.9946 - val_loss: 1.3416 - val_accuracy: 0.6997\n",
            "Epoch 26/30\n",
            "38/38 [==============================] - 35s 903ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 1.1435 - val_accuracy: 0.7460\n",
            "Epoch 27/30\n",
            "38/38 [==============================] - 35s 902ms/step - loss: 0.0180 - accuracy: 0.9930 - val_loss: 0.9160 - val_accuracy: 0.7884\n",
            "Epoch 28/30\n",
            "38/38 [==============================] - 35s 901ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.8692 - val_accuracy: 0.8016\n",
            "Epoch 29/30\n",
            "38/38 [==============================] - 35s 902ms/step - loss: 0.0098 - accuracy: 0.9955 - val_loss: 0.7953 - val_accuracy: 0.8108\n",
            "Epoch 30/30\n",
            "38/38 [==============================] - 35s 901ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 1.0494 - val_accuracy: 0.7751\n",
            "24/24 [==============================] - 3s 117ms/step - loss: 1.0494 - accuracy: 0.7751\n",
            "Test accuracy (ResNet with fine-tuning): 0.7751322984695435\n",
            "24/24 [==============================] - 4s 118ms/step\n",
            "\n",
            "Classification Report (ResNet with fine-tuning):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.90      0.52      0.66       120\n",
            "        Petra       0.92      0.80      0.85       118\n",
            "Roman_Theater       0.58      1.00      0.73       114\n",
            "     Wadi_Rum       0.94      0.91      0.92       129\n",
            "       jarash       0.93      0.52      0.66       126\n",
            "      um_qais       0.69      0.90      0.78       149\n",
            "\n",
            "     accuracy                           0.78       756\n",
            "    macro avg       0.83      0.77      0.77       756\n",
            " weighted avg       0.83      0.78      0.77       756\n",
            "\n",
            "\n",
            "Training and evaluating VGG16 with fine-tuning...\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ae421316b683>:68: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = base_model.fit_generator(train_generator, validation_data=(X_test, y_test), epochs=EPOCHS)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "38/38 [==============================] - 149s 3s/step - loss: 1.2839 - accuracy: 0.4915 - val_loss: 1.0601 - val_accuracy: 0.6098\n",
            "Epoch 2/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.6438 - accuracy: 0.7586 - val_loss: 0.9094 - val_accuracy: 0.6481\n",
            "Epoch 3/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.4894 - accuracy: 0.8177 - val_loss: 0.8810 - val_accuracy: 0.6336\n",
            "Epoch 4/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.3658 - accuracy: 0.8669 - val_loss: 0.7335 - val_accuracy: 0.7024\n",
            "Epoch 5/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.3426 - accuracy: 0.8805 - val_loss: 0.8781 - val_accuracy: 0.6825\n",
            "Epoch 6/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.2477 - accuracy: 0.9219 - val_loss: 0.7514 - val_accuracy: 0.7077\n",
            "Epoch 7/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.2125 - accuracy: 0.9272 - val_loss: 1.1196 - val_accuracy: 0.5979\n",
            "Epoch 8/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.1581 - accuracy: 0.9450 - val_loss: 0.6546 - val_accuracy: 0.7632\n",
            "Epoch 9/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.1494 - accuracy: 0.9479 - val_loss: 0.5950 - val_accuracy: 0.7923\n",
            "Epoch 10/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.1591 - accuracy: 0.9471 - val_loss: 0.5007 - val_accuracy: 0.8307\n",
            "Epoch 11/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.1489 - accuracy: 0.9467 - val_loss: 0.8748 - val_accuracy: 0.7090\n",
            "Epoch 12/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.1438 - accuracy: 0.9512 - val_loss: 0.7343 - val_accuracy: 0.7011\n",
            "Epoch 13/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.1335 - accuracy: 0.9570 - val_loss: 0.6781 - val_accuracy: 0.7765\n",
            "Epoch 14/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0610 - accuracy: 0.9797 - val_loss: 1.2660 - val_accuracy: 0.6415\n",
            "Epoch 15/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0631 - accuracy: 0.9802 - val_loss: 0.6076 - val_accuracy: 0.8108\n",
            "Epoch 16/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 1.0865 - val_accuracy: 0.6958\n",
            "Epoch 17/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0604 - accuracy: 0.9789 - val_loss: 0.8904 - val_accuracy: 0.7315\n",
            "Epoch 18/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.1060 - accuracy: 0.9644 - val_loss: 0.6811 - val_accuracy: 0.7593\n",
            "Epoch 19/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0736 - accuracy: 0.9760 - val_loss: 1.0837 - val_accuracy: 0.7011\n",
            "Epoch 20/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0515 - accuracy: 0.9789 - val_loss: 0.5931 - val_accuracy: 0.8069\n",
            "Epoch 21/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0746 - accuracy: 0.9773 - val_loss: 0.6897 - val_accuracy: 0.7593\n",
            "Epoch 22/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0834 - accuracy: 0.9694 - val_loss: 0.9407 - val_accuracy: 0.6878\n",
            "Epoch 23/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0626 - accuracy: 0.9773 - val_loss: 0.7322 - val_accuracy: 0.7632\n",
            "Epoch 24/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0382 - accuracy: 0.9851 - val_loss: 0.6859 - val_accuracy: 0.7751\n",
            "Epoch 25/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0454 - accuracy: 0.9884 - val_loss: 0.9326 - val_accuracy: 0.7011\n",
            "Epoch 26/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0510 - accuracy: 0.9814 - val_loss: 0.3910 - val_accuracy: 0.8757\n",
            "Epoch 27/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0498 - accuracy: 0.9814 - val_loss: 0.3440 - val_accuracy: 0.8955\n",
            "Epoch 28/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0343 - accuracy: 0.9876 - val_loss: 0.3427 - val_accuracy: 0.8929\n",
            "Epoch 29/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.7620 - val_accuracy: 0.7857\n",
            "Epoch 30/30\n",
            "38/38 [==============================] - 53s 1s/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.6285 - val_accuracy: 0.8386\n",
            "24/24 [==============================] - 4s 169ms/step - loss: 0.6285 - accuracy: 0.8386\n",
            "Test accuracy (VGG16 with fine-tuning): 0.8386243581771851\n",
            "24/24 [==============================] - 4s 168ms/step\n",
            "\n",
            "Classification Report (VGG16 with fine-tuning):\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Ajloun       0.66      0.88      0.75       120\n",
            "        Petra       0.88      0.91      0.89       118\n",
            "Roman_Theater       0.96      0.96      0.96       114\n",
            "     Wadi_Rum       0.99      0.69      0.81       129\n",
            "       jarash       0.99      0.72      0.83       126\n",
            "      um_qais       0.74      0.89      0.80       149\n",
            "\n",
            "     accuracy                           0.84       756\n",
            "    macro avg       0.87      0.84      0.84       756\n",
            " weighted avg       0.87      0.84      0.84       756\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
